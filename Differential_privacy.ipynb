{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826fae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Differential Privacy – Simple Queries\n",
    "# ================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def classify_utility(rel_err_pct: float) -> str:\n",
    "    if rel_err_pct < 5:\n",
    "        return \"Good\"\n",
    "    elif rel_err_pct < 15:\n",
    "        return \"Moderate\"\n",
    "    else:\n",
    "        return \"Poor\"\n",
    "\n",
    "def generalize_age_to_3bins(age_series):\n",
    "    def to_bucket(val):\n",
    "        if pd.isna(val) or str(val).strip().upper() in {\"?\", \"UNKNOWN\", \"NULL\"}:\n",
    "            return val\n",
    "        s = str(val).strip(\" []()\")\n",
    "        try:\n",
    "            low, high = map(int, s.split(\"-\", 1))\n",
    "        except:\n",
    "            return val\n",
    "        if high <= 30:\n",
    "            return \"0-30\"\n",
    "        elif high <= 60:\n",
    "            return \"30-60\"\n",
    "        else:\n",
    "            return \">60\"\n",
    "    return age_series.map(to_bucket)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Parameters\n",
    "# ------------------------------------------------\n",
    "slices = {\n",
    "    \"25k\":  \"diabetic_data_25k.csv\",\n",
    "    \"50k\":  \"diabetic_data_50k.csv\",\n",
    "    \"75k\":  \"diabetic_data_75k.csv\",\n",
    "    \"full\": \"diabetic_data_final.csv\"\n",
    "}\n",
    "\n",
    "epsilons = [2.0, 5.0, 8.0]\n",
    "\n",
    "\n",
    "epsilon_weights = {\n",
    "    \"Age-3bin counts\":             0.10,\n",
    "    \"Race counts\":                 0.10,\n",
    "    \"Gender×AdmType counts\":       0.20,\n",
    "    \"Avg # meds by age3bin\":       0.30,\n",
    "    \"Readmit(<30%) by race\":       0.30\n",
    "}\n",
    "\n",
    "# Normalize weights to compute relative ε allocation\n",
    "total_weight = sum(epsilon_weights.values())\n",
    "query_epsilons = {q: w / total_weight for q, w in epsilon_weights.items()}\n",
    "\n",
    "timing_records = []\n",
    "utility_records = []\n",
    "\n",
    "# ------------------------------------------------\n",
    "# DP Execution\n",
    "# ------------------------------------------------\n",
    "for slice_label, path in slices.items():\n",
    "    df = pd.read_csv(path, keep_default_na=False)\n",
    "    df[\"age3\"] = generalize_age_to_3bins(df[\"age\"])\n",
    "\n",
    "    true_q1 = df[\"age3\"].value_counts().reindex([\"0-30\", \"30-60\", \">60\"], fill_value=0)\n",
    "    true_q2 = df[\"race\"].value_counts().sort_index()\n",
    "    true_q3 = df.groupby([\"gender\", \"admission_type\"]).size().sort_index()\n",
    "    true_q4 = df.groupby(\"age3\")[\"num_medications\"].mean().reindex([\"0-30\", \"30-60\", \">60\"], fill_value=0)\n",
    "    true_q5 = df.groupby(\"race\")[\"readmitted\"].apply(lambda s: (s == \"<30\").mean() * 100).sort_index()\n",
    "\n",
    "    for eps in epsilons:\n",
    "        print(f\"Processing slice={slice_label}, ε={eps}\")\n",
    "\n",
    "        ### Query 1: Age-3bin counts\n",
    "        ε1 = eps * query_epsilons[\"Age-3bin counts\"]\n",
    "        scale1 = 2.0 / ε1\n",
    "        t0 = time.perf_counter()\n",
    "        noisy_q1 = true_q1 + np.random.laplace(loc=0, scale=scale1, size=len(true_q1))\n",
    "        t1 = time.perf_counter()\n",
    "        err1 = np.abs(noisy_q1 - true_q1) / true_q1.replace(0, np.nan) * 100\n",
    "        timing_records.append({\"Slice\": slice_label, \"Epsilon\": eps, \"Query\": \"Age-3bin counts\", \"Time_s\": t1 - t0})\n",
    "        utility_records.append({\"Slice\": slice_label, \"Epsilon\": eps, \"Query\": \"Age-3bin counts\", \"RelErr(%)\": err1.mean(), \"Utility\": classify_utility(err1.mean())})\n",
    "\n",
    "        ### Query 2: Race counts\n",
    "        ε2 = eps * query_epsilons[\"Race counts\"]\n",
    "        scale2 = 2.0 / ε2\n",
    "        t0 = time.perf_counter()\n",
    "        noisy_q2 = true_q2 + np.random.laplace(loc=0, scale=scale2, size=len(true_q2))\n",
    "        t1 = time.perf_counter()\n",
    "        err2 = np.abs(noisy_q2 - true_q2) / true_q2.replace(0, np.nan) * 100\n",
    "        timing_records.append({\"Slice\": slice_label, \"Epsilon\": eps, \"Query\": \"Race counts\", \"Time_s\": t1 - t0})\n",
    "        utility_records.append({\"Slice\": slice_label, \"Epsilon\": eps, \"Query\": \"Race counts\", \"RelErr(%)\": err2.mean(), \"Utility\": classify_utility(err2.mean())})\n",
    "\n",
    "        ### Query 3: Gender×AdmType\n",
    "        ε3 = eps * query_epsilons[\"Gender×AdmType counts\"]\n",
    "        scale3 = 2.0 / ε3\n",
    "        t0 = time.perf_counter()\n",
    "        noisy_q3 = true_q3 + np.random.laplace(loc=0, scale=scale3, size=len(true_q3))\n",
    "        t1 = time.perf_counter()\n",
    "        err3 = np.abs(noisy_q3 - true_q3) / true_q3.replace(0, np.nan) * 100\n",
    "        timing_records.append({\"Slice\": slice_label, \"Epsilon\": eps, \"Query\": \"Gender×AdmType counts\", \"Time_s\": t1 - t0})\n",
    "        utility_records.append({\"Slice\": slice_label, \"Epsilon\": eps, \"Query\": \"Gender×AdmType counts\", \"RelErr(%)\": err3.mean(), \"Utility\": classify_utility(err3.mean())})\n",
    "\n",
    "        ### Query 4: Avg # meds by age3bin\n",
    "        ε4 = eps * query_epsilons[\"Avg # meds by age3bin\"]\n",
    "        M_max = df[\"num_medications\"].max()\n",
    "        min_count = df[\"age3\"].value_counts().min() or 1\n",
    "        Δf4 = 2.0 * M_max / min_count\n",
    "        scale4 = Δf4 / ε4\n",
    "        t0 = time.perf_counter()\n",
    "        noisy_q4 = true_q4 + np.random.laplace(loc=0, scale=scale4, size=len(true_q4))\n",
    "        t1 = time.perf_counter()\n",
    "        err4 = np.abs(noisy_q4 - true_q4) / true_q4.replace(0, np.nan) * 100\n",
    "        timing_records.append({\"Slice\": slice_label, \"Epsilon\": eps, \"Query\": \"Avg # meds by age3bin\", \"Time_s\": t1 - t0})\n",
    "        utility_records.append({\"Slice\": slice_label, \"Epsilon\": eps, \"Query\": \"Avg # meds by age3bin\", \"RelErr(%)\": err4.mean(), \"Utility\": classify_utility(err4.mean())})\n",
    "\n",
    "        ### Query 5: Readmit% by race\n",
    "        ε5 = eps * query_epsilons[\"Readmit(<30%) by race\"]\n",
    "        min_race_n = df[\"race\"].value_counts().min() or 1\n",
    "        Δf5 = (2 / min_race_n) * 100\n",
    "        scale5 = Δf5 / ε5\n",
    "        t0 = time.perf_counter()\n",
    "        noisy_q5 = true_q5 + np.random.laplace(loc=0, scale=scale5, size=len(true_q5))\n",
    "        t1 = time.perf_counter()\n",
    "        err5 = np.abs(noisy_q5 - true_q5) / true_q5.replace(0, np.nan) * 100\n",
    "        timing_records.append({\"Slice\": slice_label, \"Epsilon\": eps, \"Query\": \"Readmit(<30%) by race\", \"Time_s\": t1 - t0})\n",
    "        utility_records.append({\"Slice\": slice_label, \"Epsilon\": eps, \"Query\": \"Readmit(<30%) by race\", \"RelErr(%)\": err5.mean(), \"Utility\": classify_utility(err5.mean())})\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Build summary tables\n",
    "# ------------------------------------------------\n",
    "df_time = pd.DataFrame(timing_records)\n",
    "df_util = pd.DataFrame(utility_records)\n",
    "\n",
    "print(\"\\n--- Timing Summary ---\")\n",
    "display(df_time)\n",
    "\n",
    "print(\"\\n--- Utility Summary (Pivot like t-closeness) ---\")\n",
    "# Create the wide utility summary identical in style to t-closeness:\n",
    "summary_pivot = (\n",
    "    df_util\n",
    "      .pivot_table(\n",
    "          index=[\"Slice\", \"Query\"],\n",
    "          columns=\"Epsilon\",\n",
    "          values=[\"RelErr(%)\", \"Utility\"],\n",
    "          aggfunc=\"first\"\n",
    "      )\n",
    "      .round(2)\n",
    ")\n",
    "summary_pivot.columns.name = None\n",
    "summary_pivot = summary_pivot.reset_index()\n",
    "display(summary_pivot)\n",
    "\n",
    "# Optional: save as CSV\n",
    "df_time.to_csv(\"dp_timing_simple_summary.csv\", index=False)\n",
    "summary_pivot.to_csv(\"dp_simple_query_utility_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Differential Privacy for Complex Queries\n",
    "# — allocate ε across queries by weight, save dp_timing_summary & dp_utility_summary\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Helper Functions\n",
    "# -----------------------------------------------------------------------------\n",
    "def classify_utility(rel_err_pct: float) -> str:\n",
    "    if rel_err_pct < 5:\n",
    "        return \"Good\"\n",
    "    elif rel_err_pct < 15:\n",
    "        return \"Moderate\"\n",
    "    else:\n",
    "        return \"Poor\"\n",
    "\n",
    "def generalize_age_to_3bins(age_series: pd.Series) -> pd.Series:\n",
    "    def to_bucket(val):\n",
    "        if pd.isna(val) or str(val).strip().upper() in {\"?\", \"UNKNOWN\", \"NULL\"}:\n",
    "            return val\n",
    "        s = str(val).strip(\" []()\")\n",
    "        try:\n",
    "            low, high = map(int, s.split(\"-\", 1))\n",
    "        except:\n",
    "            return val\n",
    "        if high <= 30:\n",
    "            return \"0-30\"\n",
    "        if high <= 60:\n",
    "            return \"30-60\"\n",
    "        return \">60\"\n",
    "    return age_series.map(to_bucket)\n",
    "\n",
    "def dp_query(true_ser: pd.Series, Δf: float, eps_q: float,\n",
    "             slice_label: str, eps: float, query_name: str,\n",
    "             timing_records: list, utility_records: list):\n",
    "    \"\"\"\n",
    "    Add Laplace noise (scale = Δf/eps_q) to true_ser,\n",
    "    record timing & compute utility.\n",
    "    \"\"\"\n",
    "    scale = Δf / eps_q\n",
    "    t0    = time.perf_counter()\n",
    "    noisy = true_ser.map(lambda v: float(v) + np.random.laplace(0, scale))\n",
    "    t1    = time.perf_counter()\n",
    "\n",
    "    # record timing\n",
    "    timing_records.append({\n",
    "        \"Slice\":   slice_label,\n",
    "        \"Epsilon\": eps,\n",
    "        \"Query\":   query_name,\n",
    "        \"Time_s\":  t1 - t0\n",
    "    })\n",
    "\n",
    "    # compute relative error & utility\n",
    "    comp = pd.DataFrame({\n",
    "        \"true\":  true_ser,\n",
    "        \"noisy\": noisy.reindex(true_ser.index).fillna(0)\n",
    "    })\n",
    "    comp[\"rel_err_pct\"] = np.where(\n",
    "        comp[\"true\"] == 0,\n",
    "        np.nan,\n",
    "        (comp[\"noisy\"] - comp[\"true\"]).abs() / comp[\"true\"] * 100\n",
    "    )\n",
    "    mean_err = comp[\"rel_err_pct\"].dropna().mean()\n",
    "    util     = classify_utility(mean_err if not np.isnan(mean_err) else 0.0)\n",
    "\n",
    "    utility_records.append({\n",
    "        \"Slice\":     slice_label,\n",
    "        \"Epsilon\":   eps,\n",
    "        \"Query\":     query_name,\n",
    "        \"RelErr(%)\": mean_err,\n",
    "        \"Utility\":   util\n",
    "    })\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Define dataset slices & global ε values\n",
    "# -----------------------------------------------------------------------------\n",
    "slices   = {\n",
    "    \"25k\":  \"diabetic_data_25k.csv\",\n",
    "    \"50k\":  \"diabetic_data_50k.csv\",\n",
    "    \"75k\":  \"diabetic_data_75k.csv\",\n",
    "    \"full\": \"diabetic_data_final.csv\"\n",
    "}\n",
    "epsilons = [2.0, 5.0, 8.0]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Define per-query ε‐allocation weights (must sum to 1.0)\n",
    "# -----------------------------------------------------------------------------\n",
    "query_weights = {\n",
    "    \"Avg LabCtrls by age3×adm\":     0.30,\n",
    "    \"Avg LabCtrls by diag2×adm\":    0.20,\n",
    "    \"Avg Meds by race×adm\":         0.20,\n",
    "    \"Avg Meds by diag2×gender\":     0.20,\n",
    "    \"Readmit% by diag1×gender\":     0.10,\n",
    "   \n",
    "    \n",
    "    \n",
    "}\n",
    "assert abs(sum(query_weights.values()) - 1.0) < 1e-6, \"Weights must sum to 1.0\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Prepare data structures to collect results\n",
    "# -----------------------------------------------------------------------------\n",
    "timing_records = []\n",
    "utility_records = []\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Core DP Pipeline: loop over slices & global epsilons\n",
    "# -----------------------------------------------------------------------------\n",
    "for slice_label, path in slices.items():\n",
    "    print(f\"\\n=== Processing slice '{slice_label}' ({path}) ===\")\n",
    "    df = pd.read_csv(path, keep_default_na=False)\n",
    "    df[\"age3\"] = generalize_age_to_3bins(df[\"age\"])\n",
    "\n",
    "    # precompute max‐ranges & minimum nonzero group‐sizes\n",
    "    max_lab  = df[\"num_lab_procedures\"].max()\n",
    "    max_meds = df[\"num_medications\"].max()\n",
    "\n",
    "    def min_group_size(cols):\n",
    "        cnt = df.groupby(cols).size()\n",
    "        return cnt[cnt > 0].min() if not cnt.empty else 1\n",
    "\n",
    "    m1 = min_group_size([\"age3\",\"admission_type\"])\n",
    "    m2 = min_group_size([\"diagnoses_2\",\"admission_type\"])\n",
    "    m3 = min_group_size([\"race\",\"admission_type\"])\n",
    "    m4 = min_group_size([\"diagnoses_2\",\"gender\"])\n",
    "    m5 = min_group_size([\"diagnoses_1\",\"gender\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # compute true-answer series\n",
    "    q1 = df.groupby([\"age3\",\"admission_type\"])[\"num_lab_procedures\"]\\\n",
    "           .mean().sort_index()\n",
    "    q2 = df.groupby([\"diagnoses_2\",\"admission_type\"])[\"num_lab_procedures\"]\\\n",
    "           .mean().sort_index()\n",
    "    q3 = df.groupby([\"race\",\"admission_type\"])[\"num_medications\"]\\\n",
    "           .mean().sort_index()\n",
    "    q4 = df.groupby([\"diagnoses_2\",\"gender\"])[\"num_medications\"]\\\n",
    "           .mean().sort_index()\n",
    "    q5 = df.groupby([\"diagnoses_1\",\"gender\"])[\"readmitted\"]\\\n",
    "           .apply(lambda s: (s==\"<30\").mean()*100).sort_index()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # loop over global epsilons\n",
    "    for eps in epsilons:\n",
    "        print(f\"  -- ε = {eps}\")\n",
    "        # allocate ε to each query\n",
    "        eps_alloc = {q: eps * w for q,w in query_weights.items()}\n",
    "\n",
    "        dp_query(\n",
    "            true_ser=q1,\n",
    "            Δf      = 2 * max_lab / m1,\n",
    "            eps_q   = eps_alloc[\"Avg LabCtrls by age3×adm\"],\n",
    "            slice_label=slice_label,\n",
    "            eps      = eps,\n",
    "            query_name=\"Avg LabCtrls by age3×adm\",\n",
    "            timing_records=timing_records,\n",
    "            utility_records=utility_records\n",
    "        )\n",
    "\n",
    "        dp_query(\n",
    "            true_ser=q2,\n",
    "            Δf      = 2 * max_lab / m2,\n",
    "            eps_q   = eps_alloc[\"Avg LabCtrls by diag2×adm\"],\n",
    "            slice_label=slice_label,\n",
    "            eps      = eps,\n",
    "            query_name=\"Avg LabCtrls by diag2×adm\",\n",
    "            timing_records=timing_records,\n",
    "            utility_records=utility_records\n",
    "        )\n",
    "        dp_query(\n",
    "            true_ser=q3,\n",
    "            Δf      = 2 * max_meds / m3,\n",
    "            eps_q   = eps_alloc[\"Avg Meds by race×adm\"],\n",
    "            slice_label=slice_label,\n",
    "            eps      = eps,\n",
    "            query_name=\"Avg Meds by race×adm\",\n",
    "            timing_records=timing_records,\n",
    "            utility_records=utility_records\n",
    "        )\n",
    "        dp_query(\n",
    "            true_ser=q4,\n",
    "            Δf      = 2 * max_meds / m4,\n",
    "            eps_q   = eps_alloc[\"Avg Meds by diag2×gender\"],\n",
    "            slice_label=slice_label,\n",
    "            eps      = eps,\n",
    "            query_name=\"Avg Meds by diag2×gender\",\n",
    "            timing_records=timing_records,\n",
    "            utility_records=utility_records\n",
    "        )\n",
    "\n",
    "        dp_query(\n",
    "            true_ser=q5,\n",
    "            Δf      = 2 * 100 / m5,\n",
    "            eps_q   = eps_alloc[\"Readmit% by diag1×gender\"],\n",
    "            slice_label=slice_label,\n",
    "            eps      = eps,\n",
    "            query_name=\"Readmit% by diag1×gender\",\n",
    "            timing_records=timing_records,\n",
    "            utility_records=utility_records\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) Build DataFrames & Summaries, save to CSV\n",
    "# -----------------------------------------------------------------------------\n",
    "df_timing  = pd.DataFrame(timing_records)\n",
    "df_utility = pd.DataFrame(utility_records)\n",
    "\n",
    "# summary of total DP time per (Slice, Epsilon) — unchanged\n",
    "dp_timing_summary = (\n",
    "    df_timing\n",
    "    .groupby([\"Slice\",\"Epsilon\"], as_index=False)[\"Time_s\"]\n",
    "    .sum()\n",
    ")\n",
    "dp_timing_summary.to_csv(\"dp_timing_complex_summary.csv\", index=False)\n",
    "\n",
    "# utility summary in the SAME format as t-closeness (wide pivot by ε)\n",
    "summary_pivot = (\n",
    "    df_utility\n",
    "      .pivot_table(\n",
    "          index=[\"Slice\", \"Query\"],\n",
    "          columns=\"Epsilon\",\n",
    "          values=[\"RelErr(%)\", \"Utility\"],\n",
    "          aggfunc=\"first\"\n",
    "      )\n",
    "      .round(2)\n",
    ")\n",
    "summary_pivot.columns.name = None\n",
    "summary_pivot = summary_pivot.reset_index()\n",
    "summary_pivot.to_csv(\"dp_complex_query_utility_summary.csv\", index=False)\n",
    "\n",
    "print(\"\\n→ Saved dp_timing_complex_summary.csv and dp_complex_query_utility_summary.csv\\n\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) (Optional) Display raw & summary tables\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"=== Raw Timing ===\")\n",
    "display(df_timing)\n",
    "\n",
    "print(\"=== Raw Utility ===\")\n",
    "display(df_utility)\n",
    "\n",
    "print(\"=== Timing Summary ===\")\n",
    "display(dp_timing_summary)\n",
    "\n",
    "print(\"=== Utility Summary (Pivot like t-closeness) ===\")\n",
    "display(summary_pivot)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7) Plot Total DP Time per Slice (stacked by ε)\n",
    "# -----------------------------------------------------------------------------\n",
    "pivot = dp_timing_summary.pivot(index=\"Slice\", columns=\"Epsilon\", values=\"Time_s\")\\\n",
    "                         .loc[[\"25k\",\"50k\",\"75k\",\"full\"]]\n",
    "plt.figure(figsize=(8,5))\n",
    "pivot.plot(kind=\"bar\")\n",
    "plt.xlabel(\"Dataset Slice\")\n",
    "plt.ylabel(\"Total DP Runtime (s)\")\n",
    "plt.title(\"Total DP Time by Slice & ε\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"ε\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
