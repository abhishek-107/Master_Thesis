{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22226719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1. Import standard packages ----\n",
    "import pandas as pd        # data handling\n",
    "import numpy as np         # (optional) numerical helpers\n",
    "import os                  # to list / verify files in the working dir\n",
    "from IPython.display import display  # nicer display in notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588a72bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 2. Read the CSV into a DataFrame ----\n",
    "csv_path = \"diabetic_data.csv\"      # <- change if your file name differs\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ---- 3. Inspect the imported dataset ----\n",
    "print(\"\\nShape of dataset (rows, columns):\", df.shape)\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# Optional: get a concise info summary\n",
    "# print(\"\\nDataFrame info():\")\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581111d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 4. Create a column subset & independent copy ----\n",
    "cols_wanted = [\n",
    "    'patient_nbr', 'race', 'gender', 'age', 'admission_type_id',\n",
    "    'num_lab_procedures', 'num_medications',\n",
    "    'diag_1', 'diag_2',\n",
    "    'metformin', 'insulin',\n",
    "    'metformin-rosiglitazone', 'metformin-pioglitazone',\n",
    "    'diabetesMed', 'readmitted'\n",
    "]\n",
    "\n",
    "# 1) Verify all requested columns exist in the original DataFrame\n",
    "missing = [c for c in cols_wanted if c not in df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"The following requested columns are not present in the DataFrame: {missing}\")\n",
    "\n",
    "# 2) Create a true copy (so further edits won’t affect df)\n",
    "subset_df = df[cols_wanted].copy()\n",
    "\n",
    "# 3) Quick look\n",
    "print(\"Subset shape:\", subset_df.shape)\n",
    "display(subset_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f88a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 6. Rename the selected columns ----\n",
    "rename_map = {\n",
    "    'patient_nbr':             'patient_number',\n",
    "    'admission_type_id':       'admission_type',\n",
    "    'diag_1':                  'diagnoses_1',\n",
    "    'diag_2':                  'diagnoses_2',\n",
    "    'metformin-rosiglitazone': 'metformin_rosiglitazone',\n",
    "    'metformin-pioglitazone':  'metformin_pioglitazone'\n",
    "}\n",
    "\n",
    "subset_df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# quick check\n",
    "print(\"Columns after renaming:\")\n",
    "print(subset_df.columns.tolist())\n",
    "display(subset_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "#  Detect and segregate rows with problematic values in two fields:\n",
    "#    • gender            – entries listed as 'Unknown/Invalid'\n",
    "#    • diagnoses_1       – NaN, empty, '?', 'UNK', 'UNKNOWN', etc.\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# 1) Flag rows where gender is 'Unknown/Invalid'\n",
    "mask_unknown_gender = subset_df['gender'].str.strip().str.upper() == 'UNKNOWN/INVALID'\n",
    "\n",
    "# 2) Flag rows where diagnoses_1 is missing / invalid\n",
    "mask_missing_diag1 = (\n",
    "    subset_df['diagnoses_1'].isna() |                              # genuine NaN\n",
    "    subset_df['diagnoses_1'].str.strip().eq('') |                  # empty string\n",
    "    subset_df['diagnoses_1'].str.strip().str.upper().isin(         # placeholders\n",
    "        {'?', 'UNK', 'UNKNOWN'}\n",
    "    )\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "#  Create convenience DataFrames\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Rows with unknown/invalid gender\n",
    "unknown_gender_df = subset_df.loc[mask_unknown_gender].copy()\n",
    "\n",
    "# Rows with missing/invalid primary diagnosis\n",
    "missing_diag1_df  = subset_df.loc[mask_missing_diag1].copy()\n",
    "\n",
    "# Clean dataset with both problems removed\n",
    "clean_df = subset_df.loc[~(mask_unknown_gender | mask_missing_diag1)].copy()\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "#  Quick counts\n",
    "# ---------------------------------------------------------------\n",
    "print(f\"Unknown/Invalid gender rows      : {len(unknown_gender_df)}\")\n",
    "print(f\"Missing/invalid diagnoses_1 rows : {len(missing_diag1_df)}\")\n",
    "print(f\"Rows retained for analysis       : {len(clean_df)} out of {len(subset_df)}\")\n",
    "\n",
    "# (Optional) peek at the problematic rows\n",
    "# unknown_gender_df.head()\n",
    "# missing_diag1_df.head()\n",
    "\n",
    "# (Optional) save or log the subsets\n",
    "# unknown_gender_df.to_csv('rows_unknown_gender.csv', index=False)\n",
    "# missing_diag1_df.to_csv('rows_missing_diag1.csv',  index=False)\n",
    "# clean_df.to_csv('subset_clean.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4cb6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "#  Remove rows with problematic gender OR primary-diagnosis values\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# 1) Build the same Boolean masks\n",
    "mask_unknown_gender = subset_df['gender'].str.strip().str.upper() == 'UNKNOWN/INVALID'\n",
    "mask_missing_diag1  = (\n",
    "    subset_df['diagnoses_1'].isna() |\n",
    "    subset_df['diagnoses_1'].str.strip().eq('') |\n",
    "    subset_df['diagnoses_1'].str.strip().str.upper().isin({'?', 'UNK', 'UNKNOWN'})\n",
    ")\n",
    "\n",
    "# 2) Combine masks: rows to drop\n",
    "rows_to_drop = mask_unknown_gender | mask_missing_diag1\n",
    "\n",
    "# 3) Drop them and create a new cleaned DataFrame\n",
    "subset_clean = subset_df.loc[~rows_to_drop].copy()\n",
    "\n",
    "# 4) Quick sanity-check\n",
    "print(f\"Rows dropped : {rows_to_drop.sum()}\")          # expected 24 (3 + 21)\n",
    "print(f\"Rows kept    : {len(subset_clean)}\")            # expected 101,742\n",
    "\n",
    "# 5) (Optional) overwrite the original variable or save to disk\n",
    "# subset_df = subset_clean           # uncomment if you want to re-use the same name\n",
    "# subset_clean.to_csv('subset_clean.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5abbee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Verify that gender and diagnoses_1 are now clean\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# 1) Gender check  ─ any Unknown/Invalid left?\n",
    "remaining_bad_gender = subset_clean['gender'].str.strip().str.upper().eq('UNKNOWN/INVALID').sum()\n",
    "\n",
    "# 2) diagnoses_1 check ─ any null / blank / placeholders left?\n",
    "remaining_bad_diag1 = (\n",
    "    subset_clean['diagnoses_1'].isna() |\n",
    "    subset_clean['diagnoses_1'].str.strip().eq('') |\n",
    "    subset_clean['diagnoses_1'].str.strip().str.upper().isin({'?', 'UNK', 'UNKNOWN'})\n",
    ").sum()\n",
    "\n",
    "print(f\"Remaining Unknown/Invalid gender rows   : {remaining_bad_gender}\")\n",
    "print(f\"Remaining missing/invalid diagnoses_1   : {remaining_bad_diag1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3656e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Inspect the 'race' column for missing / invalid values\n",
    "# ----------------------------------------------------\n",
    "invalid_tokens = {'?', 'UNK', 'UNKNOWN', 'INVALID'}   # extend if needed\n",
    "\n",
    "missing_mask = (\n",
    "    subset_clean['race'].isna() |                       # True NA (np.nan)\n",
    "    subset_clean['race'].str.strip().eq('') |           # empty string\n",
    "    subset_clean['race'].str.strip().str.upper().isin(invalid_tokens)\n",
    ")\n",
    "\n",
    "missing_race_count = missing_mask.sum()\n",
    "\n",
    "print(f\"Missing / invalid race rows : {missing_race_count} \"\n",
    "      f\"out of {len(subset_clean)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- show the offending rows ---------------------------------\n",
    "problem_rows = subset_clean[missing_mask]          # filter by the mask\n",
    "display(problem_rows)                              # pretty HTML table in Jupyter\n",
    "# or, if you prefer plain print:\n",
    "# print(problem_rows.to_string(max_rows=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf156ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Replace literal '?' in the race column with 'Missing'\n",
    "# ----------------------------------------------------\n",
    "subset_clean['race'] = (\n",
    "    subset_clean['race']                 # original column\n",
    "      .str.strip()                       # remove any leading / trailing spaces\n",
    "      .replace({'?': 'Missing'})         # map ?  ->  Missing\n",
    ")\n",
    "\n",
    "# quick check\n",
    "print(subset_clean['race'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fba8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Map admission_type codes ➜ human-readable labels\n",
    "# ----------------------------------------------------\n",
    "admission_map = {\n",
    "    1: \"Emergency\",\n",
    "    2: \"Urgent\",\n",
    "    3: \"Elective\",\n",
    "    4: \"Newborn\",\n",
    "    5: \"Not Available\",\n",
    "    6: \"NULL\",\n",
    "    7: \"Trauma Center\",\n",
    "    8: \"Not Mapped\"\n",
    "}\n",
    "\n",
    "# If the column is still string-typed, cast to numeric first (errors='coerce' keeps bad codes as NaN)\n",
    "subset_clean['admission_type'] = (\n",
    "    pd.to_numeric(subset_clean['admission_type'], errors='coerce')\n",
    "      .map(admission_map)\n",
    "      .fillna(subset_clean['admission_type'])   # fall back to original value if code wasn’t in the map\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# Quick check + preview\n",
    "# ----------------------------------------------------\n",
    "print(\"Unique values after mapping:\\n\", subset_clean['admission_type'].value_counts(dropna=False), '\\n')\n",
    "display(subset_clean.head())        # or print(subset_clean) if you really want the whole frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e59e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Check for missing / invalid values in the 'diagnoses_2' column\n",
    "# ----------------------------------------------------\n",
    "missing_diag2_mask = (\n",
    "    subset_clean['diagnoses_2'].isna()                    |  # real NA / NaN\n",
    "    subset_clean['diagnoses_2'].str.strip().eq('')        |  # empty string\n",
    "    subset_clean['diagnoses_2'].str.strip().eq('?')       |  # question-mark placeholder\n",
    "    subset_clean['diagnoses_2'].str.strip().str.upper().isin(\n",
    "        {'UNK', 'UNKNOWN', 'INVALID'}                     # other obvious placeholders\n",
    "    )\n",
    ")\n",
    "\n",
    "missing_diag2_count = missing_diag2_mask.sum()\n",
    "print(f\"Missing / invalid diagnoses_2 rows : {missing_diag2_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b2572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Replace missing / invalid values in 'diagnoses_2'\n",
    "# ----------------------------------------------------\n",
    "# (Assumes missing_diag2_mask has already been defined in the previous cell.)\n",
    "subset_clean.loc[missing_diag2_mask, 'diagnoses_2'] = 'Missing'\n",
    "\n",
    "# Optional: quick confirmation\n",
    "new_missing = subset_clean['diagnoses_2'].isna().sum() + \\\n",
    "              (subset_clean['diagnoses_2'].str.strip() == '').sum() + \\\n",
    "              (subset_clean['diagnoses_2'].str.strip().eq('?')).sum()\n",
    "print(f\"Remaining missing/invalid diagnoses_2 rows after replacement : {new_missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0651fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Remove the patient_number column\n",
    "# ----------------------------------------------------\n",
    "subset_clean = subset_clean.drop(columns=['patient_number'])\n",
    "\n",
    "# Quick check\n",
    "print(subset_clean.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79af7d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Re-order columns: put the six key columns first\n",
    "# -------------------------------------------\n",
    "first_cols = [\n",
    "    'race', 'gender', 'age',\n",
    "    'admission_type',\n",
    "    'diagnoses_1', 'diagnoses_2'\n",
    "]\n",
    "\n",
    "# Keep the remaining columns in their current order\n",
    "remaining_cols = [c for c in subset_clean.columns if c not in first_cols]\n",
    "\n",
    "# Re-assemble the DataFrame\n",
    "subset_clean = subset_clean[first_cols + remaining_cols]\n",
    "\n",
    "# Confirm the new column order\n",
    "print(subset_clean.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d47218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0)  Import anything we need\n",
    "# ============================================================\n",
    "import pandas as pd               # already imported earlier, but harmless\n",
    "\n",
    "# ============================================================\n",
    "# 1)  Function: map a raw ICD-9 code ➜ group name\n",
    "# ============================================================\n",
    "def map_icd_to_group(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert any ICD-9 code string to one of the 9 allowed group names\n",
    "        {Circulatory, Respiratory, Digestive, Diabetes, Injury,\n",
    "         Musculoskeletal, Genitourinary, Neoplasms, Other, Missing}.\n",
    "    Rules taken from Strack et al. (2014) table (screenshot).\n",
    "    • 'Missing' rows are preserved as-is.\n",
    "    • Non-numeric / E / V codes fall automatically into 'Other'.\n",
    "    \"\"\"\n",
    "    # ---- 1. preserve Missing -------------------------------------------------\n",
    "    if pd.isna(code) or str(code).strip().upper() == 'MISSING':\n",
    "        return 'Missing'\n",
    "    \n",
    "    # ---- 2. grab leading 3-digit numeric prefix (ignore .xx) -----------------\n",
    "    try:\n",
    "        prefix = int(float(str(code)[:3]))          # ‘250.01’ ➜ 250\n",
    "    except ValueError:                              # e.g. 'E878', 'V458'\n",
    "        return 'Other'\n",
    "    \n",
    "    # ---- 3. apply the figure’s rules ----------------------------------------\n",
    "    if (390 <= prefix <= 459) or prefix == 785:\n",
    "        return 'Circulatory'\n",
    "    if (460 <= prefix <= 519) or prefix == 786:\n",
    "        return 'Respiratory'\n",
    "    if (520 <= prefix <= 579) or prefix == 787:\n",
    "        return 'Digestive'\n",
    "    if prefix == 250:\n",
    "        return 'Diabetes'\n",
    "    if 800 <= prefix <= 999:\n",
    "        return 'Injury'\n",
    "    if 710 <= prefix <= 739:\n",
    "        return 'Musculoskeletal'\n",
    "    if (580 <= prefix <= 629) or prefix == 788:\n",
    "        return 'Genitourinary'\n",
    "    if 140 <= prefix <= 239:\n",
    "        return 'Neoplasms'\n",
    "    \n",
    "    # All other ICD-9 blocks and single-code leftovers\n",
    "    return 'Other'\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2)  Apply mapping to both diagnosis columns\n",
    "# ============================================================\n",
    "subset_clean = subset_clean.copy()     # keep a copy safe\n",
    "for col in ['diagnoses_1', 'diagnoses_2']:\n",
    "    subset_clean[col] = subset_clean[col].apply(map_icd_to_group)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3)  Quick sanity-checks\n",
    "# ============================================================\n",
    "\n",
    "# 3a) confirm 'Missing' counts did NOT change\n",
    "missing_counts = {col: (subset_clean[col] == 'Missing').sum()\n",
    "                  for col in ['diagnoses_1', 'diagnoses_2']}\n",
    "print(f\"‘Missing’ retained  ➜  diag_1: {missing_counts['diagnoses_1']}, \"\n",
    "      f\"diag_2: {missing_counts['diagnoses_2']}\")\n",
    "\n",
    "# 3b) list final value distribution for visual inspection\n",
    "for col in ['diagnoses_1', 'diagnoses_2']:\n",
    "    print(f\"\\nValue counts for {col}:\")\n",
    "    display(subset_clean[col].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af94b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Save the final DataFrame in the notebook’s\n",
    "# working directory (visible in “Files” pane)\n",
    "# -------------------------------------------\n",
    "\n",
    "# 1) Make an explicit copy (optional but clear)\n",
    "diabetic_data_final = subset_clean.copy()\n",
    "\n",
    "# 2) Choose a filename; no path needed → current dir\n",
    "filename = \"diabetic_data_final.csv\"\n",
    "\n",
    "# 3) Write the CSV\n",
    "diabetic_data_final.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"✔ Dataset saved as “{filename}” — {diabetic_data_final.shape[0]:,} rows, {diabetic_data_final.shape[1]} columns.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
